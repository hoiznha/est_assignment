#step1_preprocesse.py
"""
Perso.ai Q&A ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
- ì—‘ì…€ ë°ì´í„° ì½ê¸°
- Q&A ì¶”ì¶œ ë° ì •ì œ
- ë©”íƒ€ë°ì´í„° ì¶”ê°€
- JSON/CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥
"""

import pandas as pd
import json
import re
from datetime import datetime
from typing import List, Dict
import unicodedata
from pathlib import Path


class QAPreprocessor:
    """Q&A ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, excel_path: str):
        self.excel_path = excel_path
        self.qa_pairs = []
        
    def extract_qa_pairs(self) -> List[Dict]:
        """ì—‘ì…€ì—ì„œ Q&A ìŒ ì¶”ì¶œ"""
        df = pd.read_excel(self.excel_path, sheet_name='ìƒ˜í”Œ ë°ì´í„°', header=None)
        content_col = df.iloc[:, -1]
        
        qa_pairs = []
        current_q = None
        
        for idx, content in enumerate(content_col):
            if pd.isna(content):
                continue
            
            content_str = str(content).strip()
            
            if content_str.startswith('Q.'):
                current_q = content_str[2:].strip()
            elif content_str.startswith('A.') and current_q:
                current_a = content_str[2:].strip()
                qa_pairs.append({
                    'question': current_q,
                    'answer': current_a
                })
                current_q = None
        
        return qa_pairs
    
    def normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        # ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
        text = unicodedata.normalize('NFKC', text)
        
        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        return text
    
    def extract_keywords(self, text: str) -> List[str]:
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ëª…ì‚¬ ê¸°ë°˜)"""
        # ì‹¤ì œë¡œëŠ” KoNLPy ë“±ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ì§€ë§Œ, ì˜ì¡´ì„±ì„ ì¤„ì´ê¸° ìœ„í•´ ê°„ë‹¨í•œ íŒ¨í„´ ì‚¬ìš©
        keywords = []
        
        # ê³ ìœ ëª…ì‚¬ ì¶”ì¶œ íŒ¨í„´
        patterns = [
            r'Perso\.ai',
            r'ì´ìŠ¤íŠ¸ì†Œí”„íŠ¸',
            r'ESTsoft',
            r'AI',
            r'ë”ë¹™',
            r'ìŒì„±',
            r'ì˜ìƒ',
            r'ë¦½ì‹±í¬',
            r'ë‹¤êµ­ì–´'
        ]
        
        for pattern in patterns:
            if re.search(pattern, text, re.IGNORECASE):
                keywords.append(pattern.replace(r'\.', '.'))
        
        return list(set(keywords))  # ì¤‘ë³µ ì œê±°
    
    def categorize_qa(self, question: str, answer: str) -> str:
        """Q&A ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜"""
        text = question + " " + answer
        
        if any(word in text for word in ['ì„œë¹„ìŠ¤', 'í”Œë«í¼', 'ê¸°ëŠ¥', 'ì£¼ìš”']):
            return 'ì„œë¹„ìŠ¤ ì†Œê°œ'
        elif any(word in text for word in ['ì‚¬ìš©ì', 'ê³ ê°', 'ìœ íŠœë²„', 'ê¸°ì—…']):
            return 'ì‚¬ìš©ì ì •ë³´'
        elif any(word in text for word in ['ì–¸ì–´', 'ìš”ê¸ˆ', 'ê¸°ìˆ ', 'íŒŒíŠ¸ë„ˆ']):
            return 'ê¸°ìˆ  ìƒì„¸'
        elif any(word in text for word in ['ì´ìŠ¤íŠ¸ì†Œí”„íŠ¸', 'íšŒì‚¬', 'ê°œë°œ', 'ì„¤ë¦½']):
            return 'íšŒì‚¬ ì •ë³´'
        elif any(word in text for word in ['ê°€ì…', 'ì‚¬ìš©', 'ë¬¸ì˜', 'í¸ì§‘']):
            return 'ì‚¬ìš© ê°€ì´ë“œ'
        else:
            return 'ê¸°íƒ€'
    
    def add_metadata(self, qa_pairs: List[Dict]) -> List[Dict]:
        """ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
        enriched_data = []
        
        for idx, qa in enumerate(qa_pairs, 1):
            question = self.normalize_text(qa['question'])
            answer = self.normalize_text(qa['answer'])
            
            enriched_qa = {
                'id': f'qa_{idx:03d}',
                'question': question,
                'answer': answer,
                'category': self.categorize_qa(question, answer),
                'metadata': {
                    'answer_length': len(answer),
                    'keywords': self.extract_keywords(question + " " + answer),
                    'created_at': datetime.now().isoformat()
                }
            }
            
            enriched_data.append(enriched_qa)
        
        return enriched_data
    
    def generate_question_variations(self, question: str) -> List[str]:
        """ì§ˆë¬¸ ë³€í˜• ìƒì„± (ê·œì¹™ ê¸°ë°˜)"""
        variations = [question]  # ì›ë³¸ í¬í•¨
        
        # ì˜ë¬¸ì‚¬ ë³€í˜•
        variations_map = {
            'ì–´ë–¤': ['ë¬´ìŠ¨', 'ì–´ëŠ'],
            'ë¬´ì—‡ì¸ê°€ìš”': ['ë­ì˜ˆìš”', 'ë­”ê°€ìš”'],
            'ëª‡ ê°œì¸ê°€ìš”': ['ëª‡ê°œì¸ê°€ìš”', 'ëª‡ ê°œì˜ˆìš”'],
            'ì–´ë–»ê²Œ': ['ì–´ì°Œ', 'ì–´ë–»ê²Œ'],
        }
        
        for original, replacements in variations_map.items():
            if original in question:
                for replacement in replacements:
                    variations.append(question.replace(original, replacement))
        
        return list(set(variations))  # ì¤‘ë³µ ì œê±°
    
    def process(self, augment_questions: bool = False) -> List[Dict]:
        """ì „ì²´ ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸ“– Q&A ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        self.qa_pairs = self.extract_qa_pairs()
        print(f"âœ… {len(self.qa_pairs)}ê°œì˜ Q&A ìŒ ì¶”ì¶œ ì™„ë£Œ")
        
        print("\nğŸ”§ ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì¤‘...")
        self.qa_pairs = self.add_metadata(self.qa_pairs)
        print("âœ… ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì™„ë£Œ")
        
        if augment_questions:
            print("\nğŸ”„ ì§ˆë¬¸ ë³€í˜• ìƒì„± ì¤‘...")
            augmented_data = []
            for qa in self.qa_pairs:
                variations = self.generate_question_variations(qa['question'])
                for var in variations:
                    augmented_qa = qa.copy()
                    augmented_qa['question'] = var
                    augmented_qa['is_variation'] = (var != qa['question'])
                    augmented_data.append(augmented_qa)
            self.qa_pairs = augmented_data
            print(f"âœ… ì´ {len(self.qa_pairs)}ê°œë¡œ í™•ì¥ ì™„ë£Œ")
        
        return self.qa_pairs
    
    def save_to_json(self, output_path: str):
        """JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.qa_pairs, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ JSON ì €ì¥ ì™„ë£Œ: {output_path}")
    
    def save_to_csv(self, output_path: str):
        """CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        # í‰ë©´ êµ¬ì¡°ë¡œ ë³€í™˜
        flat_data = []
        for qa in self.qa_pairs:
            flat_data.append({
                'id': qa['id'],
                'question': qa['question'],
                'answer': qa['answer'],
                'category': qa['category'],
                'answer_length': qa['metadata']['answer_length'],
                'keywords': ', '.join(qa['metadata']['keywords'])
            })
        
        df = pd.DataFrame(flat_data)
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: {output_path}")
    
    def print_summary(self):
        """ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        print(f"ì´ Q&A ê°œìˆ˜: {len(self.qa_pairs)}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        categories = {}
        for qa in self.qa_pairs:
            cat = qa['category']
            categories[cat] = categories.get(cat, 0) + 1
        
        print("\nì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
        for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            print(f"  - {cat}: {count}ê°œ")
        
        # ë‹µë³€ ê¸¸ì´ í†µê³„
        lengths = [qa['metadata']['answer_length'] for qa in self.qa_pairs]
        print(f"\në‹µë³€ ê¸¸ì´ í†µê³„:")
        print(f"  - ìµœì†Œ: {min(lengths)}ì")
        print(f"  - ìµœëŒ€: {max(lengths)}ì")
        print(f"  - í‰ê· : {sum(lengths)/len(lengths):.1f}ì")
        
        print("\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")


def get_project_root() -> Path:
    """í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ë°˜í™˜"""
    # ì´ íŒŒì¼ì´ backend/ í´ë”ì— ìˆìœ¼ë¯€ë¡œ, parent.parentê°€ í”„ë¡œì íŠ¸ ë£¨íŠ¸
    return Path(__file__).resolve().parent.parent.parent.parent


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
    project_root = get_project_root()
    backend_dir = project_root / "backend"
    data_dir = backend_dir / "data"
    raw_dir = data_dir / "raw"
    processed_dir = data_dir / "processed"
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    processed_dir.mkdir(parents=True, exist_ok=True)
    
    # íŒŒì¼ ê²½ë¡œ
    excel_path = raw_dir / "Q&A.xlsx"
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not excel_path.exists():
        raise FileNotFoundError(
            f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}\n"
            f"   í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}\n"
            f"   ì˜ˆìƒ ìœ„ì¹˜: {excel_path}"
        )
    
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    preprocessor = QAPreprocessor(str(excel_path))
    
    # ê¸°ë³¸ ì „ì²˜ë¦¬ (ì§ˆë¬¸ ë³€í˜• ì—†ì´)
    qa_data = preprocessor.process(augment_questions=False)
    
    # ê²°ê³¼ ì €ì¥
    json_path = processed_dir / "qa_preprocessed.json"
    csv_path = processed_dir / "qa_preprocessed.csv"
    
    preprocessor.save_to_json(str(json_path))
    preprocessor.save_to_csv(str(csv_path))
    
    # ìš”ì•½ ì¶œë ¥
    preprocessor.print_summary()
    
    # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“ ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 2ê°œ)")
    print("="*60)
    for qa in qa_data[:2]:
        print(f"\nID: {qa['id']}")
        print(f"ì¹´í…Œê³ ë¦¬: {qa['category']}")
        print(f"ì§ˆë¬¸: {qa['question']}")
        print(f"ë‹µë³€: {qa['answer'][:50]}...")
        print(f"í‚¤ì›Œë“œ: {', '.join(qa['metadata']['keywords'])}")


if __name__ == '__main__':
    main()